{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from MoNet.flowfunc import FuncModel as fn\n",
    "import MoNet.monet as mn\n",
    "import importlib\n",
    "importlib.reload(mn)\n",
    "# importlib.reload(fn)\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 20], 30] [['fc', 'bn'], 'act']\n",
      "[10, 20] [['fc', 'bn'], ['fc', 'bn']]\n",
      "[10, 10] ['fc', 'bn']\n",
      "[20, 20] ['fc', 'bn']\n",
      "SEQ>FLOW(\n",
      "  (0:mix): SEQ>FLOW(\n",
      "    (cell-0): SEQ>FLOW(\n",
      "      (0:fc): @dup:Linear(in_features=0, out_features=10, bias=True) *id:22574603525024\n",
      "      (1:bn): @dup:BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22574603528048\n",
      "    )\n",
      "    (cell-1): SEQ>FLOW(\n",
      "      (0:fc): @dup:Linear(in_features=10, out_features=20, bias=True) *id:22574611247024\n",
      "      (1:bn): @dup:BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22574611246832\n",
      "    )\n",
      "  )\n",
      "  (1:act): @dup:GELU(approximate='none') *id:22574611245392\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myf/Skorch/.venv/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "# # 这四种等价，都是一个对一个\n",
    "# print(mn.layer('fc',10))\n",
    "# print(mn.layer('fc',[10]))\n",
    "# print(mn.layer(['fc'],10))\n",
    "# print(mn.layer(['fc'],[10]))\n",
    "\n",
    "# # 第一维度，一一对应，缺少部分重复最后一个到一样长\n",
    "# print(mn.layer('fc',[10,20]))\n",
    "# print(mn.layer(['fc'],[10,20]))\n",
    "# print(mn.layer(['fc','act'],[10,20]))\n",
    "# print(mn.layer(['fc','act'],10))\n",
    "# print(mn.layer(['fc','act'],[10]))\n",
    "\n",
    "# 在第二维度，网络代表当成一个整体，而输出代表重复\n",
    "# print(mn.layer(['fc','act'],[[10,20],30]))\n",
    "# print(mn.layer([['fc','bn'],'act'],[10,20]))\n",
    "print(mn.layer([['fc','bn'],'act'],[[10,20],30]))\n",
    "\n",
    "# 再复杂的网络采用*或者+连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, [10, 10], 1] ['dp_0.5', ['fc', 'bn', 'act', 'dp_0.5'], 'fc']\n",
      "[10, 10] [['fc', 'bn', 'act', 'dp_0.5'], ['fc', 'bn', 'act', 'dp_0.5']]\n",
      "[10, 10, 10, 10] ['fc', 'bn', 'act', 'dp_0.5']\n",
      "[10, 10, 10, 10] ['fc', 'bn', 'act', 'dp_0.5']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SEQ>FuncModel(\n",
       "  (0): SEQ>FLOW(\n",
       "    (0:dp): @dup:Dropout(p=0.5, inplace=False) *id:22463246169088\n",
       "    (1:mix): SEQ>FLOW(\n",
       "      (cell-0): SEQ>FLOW(\n",
       "        (0:fc): @dup:Linear(in_features=10, out_features=10, bias=True) *id:22463235639808\n",
       "        (1:bn): @dup:BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22466472420656\n",
       "        (2:act): @dup:GELU(approximate='none') *id:22463246168320\n",
       "        (3:dp): @dup:Dropout(p=0.5, inplace=False) *id:22463246169952\n",
       "      )\n",
       "      (cell-1): SEQ>FLOW(\n",
       "        (0:fc): @dup:Linear(in_features=10, out_features=10, bias=True) *id:22463246168560\n",
       "        (1:bn): @dup:BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22463246167792\n",
       "        (2:act): @dup:GELU(approximate='none') *id:22463246170288\n",
       "        (3:dp): @dup:Dropout(p=0.5, inplace=False) *id:22466472420992\n",
       "      )\n",
       "    )\n",
       "    (2:fc): @dup:Linear(in_features=10, out_features=1, bias=True) *id:22463246159008\n",
       "  )\n",
       "  (1): LIC>FuncModel(\n",
       "    (0): @dup:<built-in function max> *id:22463246169760\n",
       "    (1): @dup:<built-in function min> *id:22463234123152\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F=mn.Mix(0,[10,[10,10],1])\n",
    "F1=F*(fn(max)+min)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ SEQ>Mix( >>\n",
      "    tensor([[ 0.3124,  0.1198, -1.0895,  1.7064,  1.1035,  1.0846,  1.2973, -0.1490,\n",
      "         -0.6608,  1.1761],\n",
      "        [ 1.9831,  0.8707, -0.8172,  0.4615, -1.1719,  1.4913, -2.2713,  0.2525,\n",
      "          0.1307,  1.6151]])\n",
      "@ SEQ>FLOW( >>\n",
      "    tensor([[ 0.3124,  0.1198, -1.0895,  1.7064,  1.1035,  1.0846,  1.2973, -0.1490,\n",
      "         -0.6608,  1.1761],\n",
      "        [ 1.9831,  0.8707, -0.8172,  0.4615, -1.1719,  1.4913, -2.2713,  0.2525,\n",
      "          0.1307,  1.6151]])\n",
      "  0:dp : @dup:Dropout(p=0.5, inplace=False) *id:22463246169088\n",
      "  $ (tensor([[ 0.3124,  0.1198, -1.0895,  1.7064,  1.1035,  1.0846,  1.2973, -0.1490,\n",
      "         -0.6608,  1.1761],\n",
      "        [ 1.9831,  0.8707, -0.8172,  0.4615, -1.1719,  1.4913, -2.2713,  0.2525,\n",
      "          0.1307,  1.6151]]),) >>\n",
      "  == tensor([[ 0.6248,  0.2397, -0.0000,  0.0000,  0.0000,  2.1691,  2.5947, -0.2981,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.6344,  0.9229, -0.0000,  2.9827, -0.0000,  0.5050,\n",
      "          0.2615,  0.0000]])\n",
      "@ SEQ>FLOW( >>\n",
      "    tensor([[ 0.6248,  0.2397, -0.0000,  0.0000,  0.0000,  2.1691,  2.5947, -0.2981,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.6344,  0.9229, -0.0000,  2.9827, -0.0000,  0.5050,\n",
      "          0.2615,  0.0000]])\n",
      "@ SEQ>FLOW( >>\n",
      "    tensor([[ 0.6248,  0.2397, -0.0000,  0.0000,  0.0000,  2.1691,  2.5947, -0.2981,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.6344,  0.9229, -0.0000,  2.9827, -0.0000,  0.5050,\n",
      "          0.2615,  0.0000]])\n",
      "  0:fc : @dup:Linear(in_features=10, out_features=10, bias=True) *id:22463235639808\n",
      "  $ (tensor([[ 0.6248,  0.2397, -0.0000,  0.0000,  0.0000,  2.1691,  2.5947, -0.2981,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.6344,  0.9229, -0.0000,  2.9827, -0.0000,  0.5050,\n",
      "          0.2615,  0.0000]]),) >>\n",
      "  == tensor([[ 0.2933, -0.0502,  0.1073,  0.1622, -0.8511, -0.4120,  0.7331,  1.4505,\n",
      "          0.0575,  0.1838],\n",
      "        [ 0.7729,  0.8734,  0.9451,  0.3373, -0.4966, -1.3664, -0.0619,  0.7163,\n",
      "         -0.7060, -0.3194]], grad_fn=<AddmmBackward0>)\n",
      "  1:bn : @dup:BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22466472420656\n",
      "  $ (tensor([[ 0.2933, -0.0502,  0.1073,  0.1622, -0.8511, -0.4120,  0.7331,  1.4505,\n",
      "          0.0575,  0.1838],\n",
      "        [ 0.7729,  0.8734,  0.9451,  0.3373, -0.4966, -1.3664, -0.0619,  0.7163,\n",
      "         -0.7060, -0.3194]], grad_fn=<AddmmBackward0>),) >>\n",
      "  == tensor([[-0.9999, -1.0000, -1.0000, -0.9993, -0.9998,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  0.9999],\n",
      "        [ 0.9999,  1.0000,  1.0000,  0.9993,  0.9998, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -0.9999]], grad_fn=<NativeBatchNormBackward0>)\n",
      "  2:act : @dup:GELU(approximate='none') *id:22463246168320\n",
      "  $ (tensor([[-0.9999, -1.0000, -1.0000, -0.9993, -0.9998,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  0.9999],\n",
      "        [ 0.9999,  1.0000,  1.0000,  0.9993,  0.9998, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -0.9999]], grad_fn=<NativeBatchNormBackward0>),) >>\n",
      "  == tensor([[-0.1587, -0.1587, -0.1587, -0.1587, -0.1587,  0.8413,  0.8413,  0.8413,\n",
      "          0.8413,  0.8413],\n",
      "        [ 0.8413,  0.8413,  0.8413,  0.8406,  0.8412, -0.1587, -0.1587, -0.1587,\n",
      "         -0.1587, -0.1587]], grad_fn=<GeluBackward0>)\n",
      "  3:dp : @dup:Dropout(p=0.5, inplace=False) *id:22463246169952\n",
      "  $ (tensor([[-0.1587, -0.1587, -0.1587, -0.1587, -0.1587,  0.8413,  0.8413,  0.8413,\n",
      "          0.8413,  0.8413],\n",
      "        [ 0.8413,  0.8413,  0.8413,  0.8406,  0.8412, -0.1587, -0.1587, -0.1587,\n",
      "         -0.1587, -0.1587]], grad_fn=<GeluBackward0>),) >>\n",
      "  == tensor([[-0.0000, -0.0000, -0.0000, -0.3174, -0.0000,  1.6826,  1.6826,  0.0000,\n",
      "          1.6826,  0.0000],\n",
      "        [ 1.6825,  0.0000,  1.6826,  0.0000,  0.0000, -0.3173, -0.3173, -0.0000,\n",
      "         -0.3173, -0.0000]], grad_fn=<MulBackward0>)\n",
      ")>> tensor([[-0.0000, -0.0000, -0.0000, -0.3174, -0.0000,  1.6826,  1.6826,  0.0000,\n",
      "          1.6826,  0.0000],\n",
      "        [ 1.6825,  0.0000,  1.6826,  0.0000,  0.0000, -0.3173, -0.3173, -0.0000,\n",
      "         -0.3173, -0.0000]], grad_fn=<MulBackward0>)\n",
      "@ SEQ>FLOW( >>\n",
      "    tensor([[-0.0000, -0.0000, -0.0000, -0.3174, -0.0000,  1.6826,  1.6826,  0.0000,\n",
      "          1.6826,  0.0000],\n",
      "        [ 1.6825,  0.0000,  1.6826,  0.0000,  0.0000, -0.3173, -0.3173, -0.0000,\n",
      "         -0.3173, -0.0000]], grad_fn=<MulBackward0>)\n",
      "  0:fc : @dup:Linear(in_features=10, out_features=10, bias=True) *id:22463246168560\n",
      "  $ (tensor([[-0.0000, -0.0000, -0.0000, -0.3174, -0.0000,  1.6826,  1.6826,  0.0000,\n",
      "          1.6826,  0.0000],\n",
      "        [ 1.6825,  0.0000,  1.6826,  0.0000,  0.0000, -0.3173, -0.3173, -0.0000,\n",
      "         -0.3173, -0.0000]], grad_fn=<MulBackward0>),) >>\n",
      "  == tensor([[-0.2242, -0.7331,  0.3568, -0.4006, -0.4867, -0.0794, -0.0884, -0.5806,\n",
      "         -0.6295, -0.5003],\n",
      "        [-0.0999,  0.4508, -0.4112, -0.2651, -0.0508, -1.0934,  0.5191, -0.5502,\n",
      "          0.6913,  0.4884]], grad_fn=<AddmmBackward0>)\n",
      "  1:bn : @dup:BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) *id:22463246167792\n",
      "  $ (tensor([[-0.2242, -0.7331,  0.3568, -0.4006, -0.4867, -0.0794, -0.0884, -0.5806,\n",
      "         -0.6295, -0.5003],\n",
      "        [-0.0999,  0.4508, -0.4112, -0.2651, -0.0508, -1.0934,  0.5191, -0.5502,\n",
      "          0.6913,  0.4884]], grad_fn=<AddmmBackward0>),) >>\n",
      "  == tensor([[-0.9987, -1.0000,  1.0000, -0.9989, -0.9999,  1.0000, -0.9999, -0.9791,\n",
      "         -1.0000, -1.0000],\n",
      "        [ 0.9987,  1.0000, -1.0000,  0.9989,  0.9999, -1.0000,  0.9999,  0.9791,\n",
      "          1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n",
      "  2:act : @dup:GELU(approximate='none') *id:22463246170288\n",
      "  $ (tensor([[-0.9987, -1.0000,  1.0000, -0.9989, -0.9999,  1.0000, -0.9999, -0.9791,\n",
      "         -1.0000, -1.0000],\n",
      "        [ 0.9987,  1.0000, -1.0000,  0.9989,  0.9999, -1.0000,  0.9999,  0.9791,\n",
      "          1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>),) >>\n",
      "  == tensor([[-0.1588, -0.1587,  0.8413, -0.1587, -0.1587,  0.8413, -0.1587, -0.1603,\n",
      "         -0.1587, -0.1587],\n",
      "        [ 0.8399,  0.8413, -0.1587,  0.8402,  0.8412, -0.1587,  0.8413,  0.8188,\n",
      "          0.8413,  0.8413]], grad_fn=<GeluBackward0>)\n",
      "  3:dp : @dup:Dropout(p=0.5, inplace=False) *id:22466472420992\n",
      "  $ (tensor([[-0.1588, -0.1587,  0.8413, -0.1587, -0.1587,  0.8413, -0.1587, -0.1603,\n",
      "         -0.1587, -0.1587],\n",
      "        [ 0.8399,  0.8413, -0.1587,  0.8402,  0.8412, -0.1587,  0.8413,  0.8188,\n",
      "          0.8413,  0.8413]], grad_fn=<GeluBackward0>),) >>\n",
      "  == tensor([[-0.3175, -0.0000,  1.6826, -0.3175, -0.3173,  0.0000, -0.0000, -0.3207,\n",
      "         -0.0000, -0.3173],\n",
      "        [ 0.0000,  0.0000, -0.0000,  1.6803,  1.6825, -0.3173,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<MulBackward0>)\n",
      ")>> tensor([[-0.3175, -0.0000,  1.6826, -0.3175, -0.3173,  0.0000, -0.0000, -0.3207,\n",
      "         -0.0000, -0.3173],\n",
      "        [ 0.0000,  0.0000, -0.0000,  1.6803,  1.6825, -0.3173,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<MulBackward0>)\n",
      ")>> tensor([[-0.3175, -0.0000,  1.6826, -0.3175, -0.3173,  0.0000, -0.0000, -0.3207,\n",
      "         -0.0000, -0.3173],\n",
      "        [ 0.0000,  0.0000, -0.0000,  1.6803,  1.6825, -0.3173,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<MulBackward0>)\n",
      "  2:fc : @dup:Linear(in_features=10, out_features=1, bias=True) *id:22463246159008\n",
      "  $ (tensor([[-0.3175, -0.0000,  1.6826, -0.3175, -0.3173,  0.0000, -0.0000, -0.3207,\n",
      "         -0.0000, -0.3173],\n",
      "        [ 0.0000,  0.0000, -0.0000,  1.6803,  1.6825, -0.3173,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<MulBackward0>),) >>\n",
      "  == tensor([[ 0.3060],\n",
      "        [-0.3956]], grad_fn=<AddmmBackward0>)\n",
      ")>> tensor([[ 0.3060],\n",
      "        [-0.3956]], grad_fn=<AddmmBackward0>)\n",
      ")>> tensor([[ 0.3060],\n",
      "        [-0.3956]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3060],\n",
       "        [-0.3956]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.p(torch.randn(2,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.venv]",
   "language": "python",
   "name": "conda-env-.venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
